{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A novel loss function to improve generalisation in neural networks\n",
    "\n",
    "This loss function is the basis of my dissertation. We seek to support the generalisation of neural networks through a novel loss function: Correlation Penalty Loss (CP Loss). We derive a correlation measure between a network’s activations and a set of labels associated with an orthogonal task. For example, the speaker’s gender is orthogonal in a word recognition task. \n",
    "\n",
    "**Experimental work**\n",
    "We implement CPL and experiment with audio and image classification tasks using Convolutional Neural Networks. In addition to using existing orthogonal tasks, we use data augmentation strategies, such as adding noise to create orthogonal labels. This latter point relieves us from the constraint of sourcing or the expense of collecting data with these additional labels. \n",
    "\n",
    "**Results**\n",
    "The experimental results showed some positive effects of using CP Loss, with a statistically significant result in reducing the standard deviation of the accuracy scores between orthogonal classes in an image classification task (using CIFAR-10 and labels generated by data augmentation).\n",
    "\n",
    "**Credits**\n",
    "My supervisor for this project was Dr Tillman Weyde (https://www.city.ac.uk/about/people/academics/tillman-weyde) and many thanks to Dr Eric Guizzo for his support and whose work inspired this project (https://arxiv.org/abs/2006.06494)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "from cp_loss import CorrelationPenaltyLoss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple MLP\n",
    "# takes 10 input features and outputs 10 features\n",
    "class MyMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(50, 20)\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random dataset\n",
    "# input\n",
    "input = torch.randn(64, 10)\n",
    "v_input = torch.randn(16,10)\n",
    "t_input = torch.randn(8,10)\n",
    "\n",
    "# \"true\" labels int 0-9\n",
    "target = torch.randint(0, 10, (64,))\n",
    "v_target = torch.randint(0, 10, (16,))\n",
    "t_target = torch.randint(0, 10, (8,))\n",
    "\n",
    "# orthogonal labels int 0-2\n",
    "orthogonal_labels = torch.randint(0, 3, (64,))\n",
    "v_orthogonal_labels = torch.randint(0, 3, (16,))\n",
    "t_orthogonal_labels = torch.randint(0, 3, (8,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, validation loss: 2.36, time:0.03\n",
      "epoch: 2, validation loss: 1.18, time:0.01\n",
      "epoch: 3, validation loss: 0.79, time:0.00\n",
      "epoch: 4, validation loss: 0.59, time:0.00\n",
      "epoch: 5, validation loss: 0.47, time:0.01\n",
      "epoch: 6, validation loss: 0.39, time:0.00\n",
      "epoch: 7, validation loss: 0.34, time:0.00\n",
      "epoch: 8, validation loss: 0.29, time:0.00\n",
      "epoch: 9, validation loss: 0.26, time:0.00\n",
      "epoch: 10, validation loss: 0.24, time:0.00\n"
     ]
    }
   ],
   "source": [
    "# set up training\n",
    "model = MyMLP()\n",
    "base_loss_fn = nn.CrossEntropyLoss()\n",
    "criterion=CorrelationPenaltyLoss(base_loss_fn=base_loss_fn, \n",
    "                                 model=model,\n",
    "                                 layer_type=\"nn.Linear\",\n",
    "                                 num_orthog_classes=3,\n",
    "                                 one_hot=True,\n",
    "                                 alpha=10)\n",
    "optimizer = optim.Adam(params=model.parameters())\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "# for validation\n",
    "val_err = torch.zeros(n_epochs)\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    t0=time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input)\n",
    "    loss = criterion(output, target, orthogonal_labels)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # validation loss\n",
    "    model.eval()\n",
    "    running_vloss = 0.\n",
    "    with torch.no_grad():\n",
    "        v_output = model(v_input)\n",
    "        vloss = base_loss_fn(v_output, v_target)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (epoch + 1)\n",
    "    val_err[epoch]=avg_vloss\n",
    "    print(f\"epoch: {epoch+1}, validation loss: {avg_vloss:0.2f}, time:{time.time()-t0:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1 / 8 with accuracy 12.50\n"
     ]
    }
   ],
   "source": [
    "# accuracy - should not be better than random chance (~10%)! \n",
    "num_correct = 0\n",
    "num_samples = 0\n",
    "model.eval()\n",
    " \n",
    "with torch.no_grad():  \n",
    "    scores=model(t_input)\n",
    "    _, predictions = scores.max(1)\n",
    "    num_correct += (predictions == t_target).sum()\n",
    "    num_samples += predictions.size(0)\n",
    "\n",
    "print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
